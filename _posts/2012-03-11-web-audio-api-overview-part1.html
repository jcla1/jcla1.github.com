---
layout: post
title: Web Audio API overview (Part 1 of 2)
date: 2012-03-11
abstract: Looks into creating a simple audio visualizer, which is extended in the <a href="/blog/2012/04/06/web-audio-api-overview-part2/">second part</a>.
redirect_from: /blog/2012/03/11/web-audio-api-overview-part1/
---

<p>In the next 2 blog posts I'll be showing you some essential features of the Web Audio API. You can find its specification <a href="https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html">here</a>.
The Web Audio API provides nearly all the functionality of a normal synthesizer, one of the reasons why it is so powerful.</p>

<p>Anyway let's get going. I'm going to talk you through the source of a little audio visualizer in this post and the next one. <a href="/iframes/web_audio_final.html">Here is a demo of the final product.</a>
In this first post I'll concentrate on <a href="/iframes/web_audio_intro.html">a simplified version</a>.</p>


<p class="warning"><b>Warning:</b>  The code shown in this blog post is outdated and will only work in older version of Chrome.</p>

<p>Now let's look at the HTML body structure. In this case it is very simple, it has a main <code>#container</code>, that (as the name says) contains a canvas and an audio element. After that there are a couple of script tags. </p>

<pre><code class="html">
&lt;body&gt;
  &lt;div id=&quot;container&quot;&gt;
    &lt;canvas height=&quot;200&quot; width=&quot;500&quot; id=&quot;fft&quot;&gt;&lt;/canvas&gt;
    &lt;audio id=&quot;audio&quot; src=&quot;IO2010.mp3&quot; preload controls&gt;&lt;/audio&gt;
  &lt;/div&gt;
  &lt;script&gt;
  // requestAnim shim layer by Paul Irish
    window.requestAnimFrame = (function(){
      return  window.requestAnimationFrame       ||
              window.webkitRequestAnimationFrame ||
              window.mozRequestAnimationFrame    ||
              window.oRequestAnimationFrame      ||
              window.msRequestAnimationFrame     ||
              function(callback, element){
                window.setTimeout(callback, 1000 / 60);
              };
    })();
  &lt;/script&gt;
  &lt;script&gt;
    // Some Javascript
  &lt;/script&gt;
&lt;/body&gt;
</code></pre>

<p>You may already know what the contents of the first script tag are for.
It is a shim by <a href="http://paulirish.com">Paul Irish</a> that makes it easier to use the <code>requestAnimationFrame()</code> (To get more info read his <a href="http://paulirish.com/2011/requestanimationframe-for-smart-animating/">blog post</a>). I'm not going to go further into how it works, but all it does <em>really</em> is make user friendlier animations.</p>

<p>The important parts for this blog post are the contents of the 2nd script tag:</p>

<pre><code>
// The audio element
audioElement = document.getElementById('audio');

// The canvas, its context and fillstyle
canvas = document.getElementById('fft');
ctx = canvas.getContext('2d');
ctx.fillStyle = "white";

// Create new Audio Context and an audio analyzer
audioContext = new webkitAudioContext();
analyser = audioContext.createAnalyser();

// Canvas' height and width
CANVAS_HEIGHT = canvas.height;
CANVAS_WIDTH = canvas.width;
// We'll need the offset later
OFFSET = 100;
// Spacing between the individual bars
SPACING = 10;
// Initialize and start drawing
// when the audio starts playing
window.onload = init;
audioElement.addEventListener('play', draw);

function init() {
  // Take input from audioElement
  source = audioContext.createMediaElementSource(audioElement);
  // Connect the stream to an analyzer
  source.connect(analyser);
  // Connect the analyzer to the speakers
  analyser.connect(audioContext.destination);
  // Start the animation
  draw();
}

function draw() {
  // See http://paulirish.com/2011/requestanimationframe-for-smart-animating/
  requestAnimFrame(draw, canvas);
  // New typed array for the raw frequency data
  freqData = new Uint8Array(analyser.frequencyBinCount);
  // Put the raw frequency into the newly created array
  analyser.getByteFrequencyData(freqData);
  // Clear the canvas
  ctx.clearRect(0, 0, CANVAS_WIDTH, CANVAS_HEIGHT);
  // This loop draws all the bars
  for (var i = 0; i < freqData.length - OFFSET; i++) {
    // Work out the hight of the current bar
    // by getting the current frequency
    var magnitude = freqData[i + OFFSET];
    // Draw a bar from the bottom up (cause for the "-magnitude")
    ctx.fillRect(i * SPACING, CANVAS_HEIGHT, SPACING / 2, -magnitude);
  };
}
</code></pre>

<p>The <code>webkitAudioContext()</code> created, is a context in which the audio interactions take place. Similar to the ones mentioned in my <a href="/blog/2012/01/08/exploring-the-v8-js-engine-part-2/">previous post</a>.</p>

<p>You could divide it into 2 main parts:</p>
<ul>
  <li><p>The setup</p></li>
  <li><p>The animation's <code>draw</code> function</p></li>
</ul>

<h2>The setup</h2>

<p>sets up all the variables (except "freqData") and provides information on how each bar drawn should look.
The <code>init</code> function connects the source of the audio (the audio element) with the analyzer and connects the analyzer with the destination. i.e. the speakers</p>

<p>You can imagine connecting up <code>source</code>, <code>analyzer</code> and <code>destination</code> as taking a few plugs and plugging them in some hardware.
The only difference is that this is virtual!</p>

<h2>The animation's draw() function</h2>

<p>takes care of drawing the bars.</p>

<p>But what does that mean <em>exactly</em>?</p>

<ol>
<li><p>Call the <code>requestAnimFrame</code> function to restart the animation at just the right time.</p></li>
<li><p>Create a typed array (called <code>freqData</code>) for holding the individual frequencies.
The parameter passed at creation is the size of the array (In this case <code>1024</code> items).</p></li>
<li><p>Call a function on the analyzer to put the frequencies in <code>freqData</code> (it doesn't return anything). </p></li>
<li><p>Simply clear the canvas.</p></li>
<li><p>Loop through all the frequency data (except that in the offset) and each time:</p>

<ul><li><p>Get the current frequency</p></li>
<li><p>Draw a bar that is as high as the frequency. The magnitude has to be negative here so that the bar is drawn in the correct direction.</p></li></ul></li>
<li><p>Lather. Rinse. Repeat.</p></li>
</ol>

<p>Nearly everything that has to do with the Web Audio API inherits from an object called <code>AudioNode</code>, which contains some basic structure for working with audio.
For example the analyzer we are using here is also inherited from <code>AudioNode</code>. Other examples of Audio Nodes are <code>BiquadFilter</code>, <code>LowPassFilter</code>, <code>AudioGainNode</code> and many more. I will be covering some of them in part 2 of this mini series.</p>

